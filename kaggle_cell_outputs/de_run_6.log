2025-08-31 09:33:06.412909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756632786.598592      97 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756632786.653974      97 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/models/convmixer.py:88: UserWarning: Overwriting convmixer_1536_20 in registry with utils.models.convmixer.convmixer_1536_20. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/models/convmixer.py:94: UserWarning: Overwriting convmixer_768_32 in registry with utils.models.convmixer.convmixer_768_32. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/models/convmixer.py:100: UserWarning: Overwriting convmixer_1024_20_ks9_p14 in registry with utils.models.convmixer.convmixer_1024_20_ks9_p14. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model
/usr/local/lib/python3.11/dist-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/models/tnt.py:258: UserWarning: Overwriting tnt_s_patch16_224 in registry with utils.models.tnt.tnt_s_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/models/tnt.py:267: UserWarning: Overwriting tnt_b_patch16_224 in registry with utils.models.tnt.tnt_b_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/tools/utility.py:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
create dataset: cifar100
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Creating model...sew_34,
 number of params: 27599012
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_20.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_20.pt'
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_2_40.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_2_40.pt'
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_3_30.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_3_30.pt'
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_40.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_40.pt'
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_4_30.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-2_4_30.pt'
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-3_30.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-3_30.pt'
/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-4_30.pt
Loaded  from checkpoint '/kaggle/working/AML-Project/pretrain_cifar_100_using_resuming_cifar_10_lr_1-4_30.pt'
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/main_cosde.py:443: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp_autocast():
data_time: 0.000 (0.003)  batch_time: 1.615 (1.380)  
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/tools/val.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp_autocast():
Test: [   0/78]  Time: 1.066 (1.066)  DataTime: 0.641 (0.641)  Loss:  1.5781 (1.5781)  F1: 35.3143 (35.3143)  Acc@1: 56.2500 (56.2500)  Acc@5: 85.1562 (85.1562)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.013)  Loss:  1.8857 (1.7470)  F1: 38.2835 (35.5024)  Acc@1: 53.9062 (52.8646)  Acc@5: 75.0000 (82.2304)
Test: [  78/78]  Time: 0.291 (0.208)  DataTime: 0.000 (0.008)  Loss:  2.3145 (1.7465)  F1:  5.6667 (35.6622)  Acc@1: 37.5000 (52.8000)  Acc@5: 68.7500 (82.1800)
metrics: OrderedDict([('loss', 1.7465), ('top1', 52.8), ('top5', 82.18), ('f1', 35.662)])
metrics_f1: 35.662
Test: [   0/78]  Time: 1.151 (1.151)  DataTime: 0.951 (0.951)  Loss:  1.1367 (1.1367)  F1: 46.7429 (46.7429)  Acc@1: 71.8750 (71.8750)  Acc@5: 90.6250 (90.6250)
Test: [  50/78]  Time: 0.196 (0.215)  DataTime: 0.000 (0.019)  Loss:  1.3887 (1.2173)  F1: 47.4119 (47.8551)  Acc@1: 66.4062 (68.7806)  Acc@5: 89.8438 (91.3603)
Test: [  78/78]  Time: 0.029 (0.206)  DataTime: 0.000 (0.012)  Loss:  0.9121 (1.2142)  F1: 10.0000 (48.4951)  Acc@1: 68.7500 (69.1500)  Acc@5: 100.0000 (91.4200)
metrics: OrderedDict([('loss', 1.2142), ('top1', 69.15), ('top5', 91.42), ('f1', 48.495)])
metrics_f1: 48.495
Test: [   0/78]  Time: 1.039 (1.039)  DataTime: 0.739 (0.739)  Loss:  1.1758 (1.1758)  F1: 44.6452 (44.6452)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.8438 (89.8438)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.015)  Loss:  1.3496 (1.2403)  F1: 44.7746 (45.9127)  Acc@1: 62.5000 (65.9007)  Acc@5: 91.4062 (90.6250)
Test: [  78/78]  Time: 0.028 (0.204)  DataTime: 0.000 (0.010)  Loss:  0.8613 (1.2318)  F1: 11.6667 (46.5573)  Acc@1: 75.0000 (66.5500)  Acc@5: 93.7500 (90.8400)
metrics: OrderedDict([('loss', 1.2318), ('top1', 66.55), ('top5', 90.84), ('f1', 46.557)])
metrics_f1: 46.557
Test: [   0/78]  Time: 1.335 (1.335)  DataTime: 1.138 (1.138)  Loss:  1.1016 (1.1016)  F1: 43.9667 (43.9667)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test: [  50/78]  Time: 0.196 (0.218)  DataTime: 0.000 (0.023)  Loss:  1.2695 (1.1817)  F1: 48.2333 (46.2972)  Acc@1: 67.1875 (66.5748)  Acc@5: 87.5000 (90.5944)
Test: [  78/78]  Time: 0.030 (0.208)  DataTime: 0.000 (0.015)  Loss:  1.0137 (1.1900)  F1: 12.0000 (46.1194)  Acc@1: 81.2500 (66.2900)  Acc@5: 87.5000 (90.5300)
metrics: OrderedDict([('loss', 1.19), ('top1', 66.29), ('top5', 90.53), ('f1', 46.119)])
metrics_f1: 46.119
Test: [   0/78]  Time: 0.878 (0.878)  DataTime: 0.642 (0.642)  Loss:  1.1230 (1.1230)  F1: 45.6476 (45.6476)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test: [  50/78]  Time: 0.196 (0.212)  DataTime: 0.000 (0.015)  Loss:  1.4375 (1.3409)  F1: 47.0429 (46.6297)  Acc@1: 64.8438 (66.8045)  Acc@5: 92.1875 (90.3339)
Test: [  78/78]  Time: 0.028 (0.204)  DataTime: 0.000 (0.010)  Loss:  1.5723 (1.3364)  F1:  9.6667 (46.7877)  Acc@1: 62.5000 (66.9300)  Acc@5: 81.2500 (90.6400)
metrics: OrderedDict([('loss', 1.3364), ('top1', 66.93), ('top5', 90.64), ('f1', 46.788)])
metrics_f1: 46.788
Test: [   0/78]  Time: 0.821 (0.821)  DataTime: 0.613 (0.613)  Loss:  2.5430 (2.5430)  F1: 17.8095 (17.8095)  Acc@1: 32.0312 (32.0312)  Acc@5: 66.4062 (66.4062)
Test: [  50/78]  Time: 0.196 (0.208)  DataTime: 0.000 (0.013)  Loss:  2.7461 (2.6626)  F1: 18.5476 (18.1193)  Acc@1: 34.3750 (29.8866)  Acc@5: 66.4062 (66.7586)
Test: [  78/78]  Time: 0.028 (0.202)  DataTime: 0.000 (0.008)  Loss:  2.6270 (2.6705)  F1:  6.0000 (18.0933)  Acc@1: 43.7500 (29.6200)  Acc@5: 62.5000 (66.7200)
metrics: OrderedDict([('loss', 2.6705), ('top1', 29.62), ('top5', 66.72), ('f1', 18.093)])
metrics_f1: 18.093
Test: [   0/78]  Time: 1.141 (1.141)  DataTime: 0.941 (0.941)  Loss:  4.3711 (4.3711)  F1:  2.8389 ( 2.8389)  Acc@1: 10.9375 (10.9375)  Acc@5: 28.1250 (28.1250)
Test: [  50/78]  Time: 0.196 (0.214)  DataTime: 0.000 (0.019)  Loss:  4.3906 (4.3887)  F1:  3.8088 ( 3.0342)  Acc@1:  9.3750 ( 7.9350)  Acc@5: 28.9062 (28.2322)
Test: [  78/78]  Time: 0.029 (0.206)  DataTime: 0.000 (0.012)  Loss:  4.4180 (4.3930)  F1:  0.0000 ( 2.9464)  Acc@1:  0.0000 ( 7.6200)  Acc@5: 12.5000 (27.6300)
metrics: OrderedDict([('loss', 4.393), ('top1', 7.62), ('top5', 27.63), ('f1', 2.946)])
metrics_f1: 2.946
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/tools/val.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp_autocast():
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/tools/val.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp_autocast():
Test: [   0/78]  Time: 2.522 (2.522)  DataTime: 0.816 (0.816)  Loss:  4.2148 (2.7075)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  50/78]  Time: 1.576 (1.598)  DataTime: 0.000 (0.016)  Loss:  4.2578 (2.7868)  Acc@1: 70.3125 (72.3958)  Acc@5: 93.7500 (93.7347)
Test: [  78/78]  Time: 0.277 (1.574)  DataTime: 0.000 (0.011)  Loss:  4.2500 (2.7861)  Acc@1: 68.7500 (72.5400)  Acc@5: 93.7500 (93.7900)
ensemble_metrics_top1: 72.54
epoch:0, best_score:78.2621, best_idx:1,                      score: [tensor(53.1146), tensor(78.2621), tensor(73.1694), tensor(71.8003), tensor(72.6830), tensor(28.1374), tensor(7.1407)]
score [tensor(53.1146), tensor(78.2621), tensor(73.1694), tensor(71.8003), tensor(72.6830), tensor(28.1374), tensor(7.1407)]
cr f 1e-05 1e-05
/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/tools/de.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp_autocast():
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.322 (0.394)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.322 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.322 (0.394)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
[tensor(53.1074), tensor(78.5322), tensor(73.3828), tensor(71.7044), tensor(73.0535), tensor(28.0874), tensor(7.0492)]
[0, 1, 1, 1, 1, 1, 0]
epoch:0, best_score:78.5322, best_idx:1,                      score: [tensor(53.1833), tensor(78.5322), tensor(73.3828), tensor(71.7044), tensor(73.0535), tensor(28.0874), tensor(7.0692)]
Best in train_set update and train acc =  tensor(78.5322)
Saving model to ./output/train/20250831-093329-run_6/train_best_sew_34.pt
Test: [   0/78]  Time: 1.109 (1.109)  DataTime: 0.857 (0.857)  Loss:  1.1348 (1.1348)  F1: 46.4714 (46.4714)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test: [  50/78]  Time: 0.196 (0.214)  DataTime: 0.000 (0.017)  Loss:  1.4189 (1.2240)  F1: 46.2603 (47.6605)  Acc@1: 64.8438 (68.4589)  Acc@5: 89.0625 (91.1918)
Test: [  78/78]  Time: 0.031 (0.205)  DataTime: 0.000 (0.011)  Loss:  0.9678 (1.2166)  F1: 10.0000 (48.1802)  Acc@1: 68.7500 (68.8100)  Acc@5: 93.7500 (91.3200)
metrics: OrderedDict([('loss', 1.2166), ('top1', 68.81), ('top5', 91.32), ('f1', 48.18)])
metrics_f1: 48.18
Best in train_set update and val acc =  68.81
Saving best val model to ./output/train/20250831-093329-run_6/val_best_sew_34.pt
Saving best val solution to ./output/train/20250831-093329-run_6/val_best_sew_34_solution.pt
Test: [   0/78]  Time: 1.084 (1.084)  DataTime: 0.871 (0.871)  Loss:  1.1133 (1.1133)  F1: 46.5143 (46.5143)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.017)  Loss:  1.3789 (1.2353)  F1: 46.3320 (46.1267)  Acc@1: 63.2812 (66.4062)  Acc@5: 89.0625 (90.3646)
Test: [  78/78]  Time: 0.030 (0.205)  DataTime: 0.000 (0.011)  Loss:  0.8101 (1.2281)  F1: 12.0000 (46.4766)  Acc@1: 81.2500 (66.6700)  Acc@5: 93.7500 (90.5500)
metrics: OrderedDict([('loss', 1.2281), ('top1', 66.67), ('top5', 90.55), ('f1', 46.477)])
metrics_f1: 46.477
Test: [   0/78]  Time: 0.995 (0.995)  DataTime: 0.702 (0.702)  Loss:  1.0156 (1.0156)  F1: 45.0000 (45.0000)  Acc@1: 70.3125 (70.3125)  Acc@5: 91.4062 (91.4062)
Test: [  50/78]  Time: 0.196 (0.212)  DataTime: 0.000 (0.014)  Loss:  1.3135 (1.1801)  F1: 46.5667 (46.1307)  Acc@1: 64.0625 (66.3756)  Acc@5: 86.7188 (90.7169)
Test: [  78/78]  Time: 0.028 (0.204)  DataTime: 0.000 (0.009)  Loss:  1.3135 (1.1881)  F1: 10.6667 (46.1818)  Acc@1: 68.7500 (66.2800)  Acc@5: 87.5000 (90.5800)
metrics: OrderedDict([('loss', 1.1881), ('top1', 66.28), ('top5', 90.58), ('f1', 46.182)])
metrics_f1: 46.182
Test: [   0/78]  Time: 0.843 (0.843)  DataTime: 0.586 (0.586)  Loss:  1.1484 (1.1484)  F1: 44.5270 (44.5270)  Acc@1: 69.5312 (69.5312)  Acc@5: 93.7500 (93.7500)
Test: [  50/78]  Time: 0.196 (0.209)  DataTime: 0.000 (0.012)  Loss:  1.4609 (1.3365)  F1: 49.8619 (46.6825)  Acc@1: 67.1875 (67.1415)  Acc@5: 89.0625 (90.4105)
Test: [  78/78]  Time: 0.029 (0.202)  DataTime: 0.000 (0.008)  Loss:  1.5498 (1.3300)  F1:  9.6667 (47.1629)  Acc@1: 62.5000 (67.4500)  Acc@5: 81.2500 (90.7200)
metrics: OrderedDict([('loss', 1.33), ('top1', 67.45), ('top5', 90.72), ('f1', 47.163)])
metrics_f1: 47.163
Test: [   0/78]  Time: 1.053 (1.053)  DataTime: 0.758 (0.758)  Loss:  2.5410 (2.5410)  F1: 17.8667 (17.8667)  Acc@1: 32.0312 (32.0312)  Acc@5: 67.9688 (67.9688)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.015)  Loss:  2.7383 (2.6624)  F1: 18.8476 (18.1161)  Acc@1: 33.5938 (29.8254)  Acc@5: 67.1875 (67.0037)
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.010)  Loss:  2.6523 (2.6698)  F1:  5.3333 (18.1093)  Acc@1: 37.5000 (29.6000)  Acc@5: 62.5000 (66.8400)
metrics: OrderedDict([('loss', 2.6698), ('top1', 29.6), ('top5', 66.84), ('f1', 18.109)])
metrics_f1: 18.109
score: [53, 78, 73, 72, 73, 28, 7]
DE:1 Acc@1: 68.8100 Acc@5: 91.3200                          Epoch_time: 1167.644s
cr f 1.3541951485497447e-05 1.493492243535156e-05
data_time: 0.000 (0.003)  batch_time: 0.322 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.322 (0.395)  
data_time: 0.000 (0.005)  batch_time: 0.321 (0.397)  
[tensor(53.0207), tensor(78.4874), tensor(73.3060), tensor(71.8846), tensor(72.7833), tensor(28.1722), tensor(7.1831)]
[0, 1, 1, 1, 1, 1, 1]
epoch:0, best_score:78.4874, best_idx:1,                      score: [tensor(53.1206), tensor(78.4874), tensor(73.3060), tensor(71.8846), tensor(72.7833), tensor(28.1722), tensor(7.1831)]
Test: [   0/78]  Time: 1.038 (1.038)  DataTime: 0.826 (0.826)  Loss:  1.1357 (1.1357)  F1: 47.6381 (47.6381)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.017)  Loss:  1.3887 (1.2204)  F1: 47.6794 (47.9679)  Acc@1: 67.9688 (68.6887)  Acc@5: 88.2812 (91.0999)
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.011)  Loss:  1.0498 (1.2148)  F1: 10.0000 (48.5335)  Acc@1: 68.7500 (69.1700)  Acc@5: 93.7500 (91.3600)
metrics: OrderedDict([('loss', 1.2148), ('top1', 69.17), ('top5', 91.36), ('f1', 48.533)])
metrics_f1: 48.533
Best in train_set update and val acc =  69.17
Saving best val model to ./output/train/20250831-093329-run_6/val_best_sew_34.pt
Saving best val solution to ./output/train/20250831-093329-run_6/val_best_sew_34_solution.pt
Test: [   0/78]  Time: 0.818 (0.818)  DataTime: 0.601 (0.601)  Loss:  1.1279 (1.1279)  F1: 46.7452 (46.7452)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test: [  50/78]  Time: 0.196 (0.210)  DataTime: 0.000 (0.012)  Loss:  1.3730 (1.2388)  F1: 44.5048 (45.7581)  Acc@1: 63.2812 (65.9620)  Acc@5: 90.6250 (90.4412)
Test: [  78/78]  Time: 0.029 (0.203)  DataTime: 0.000 (0.008)  Loss:  1.0283 (1.2319)  F1: 11.0000 (46.4159)  Acc@1: 75.0000 (66.5500)  Acc@5: 93.7500 (90.4800)
metrics: OrderedDict([('loss', 1.2319), ('top1', 66.55), ('top5', 90.48), ('f1', 46.416)])
metrics_f1: 46.416
Test: [   0/78]  Time: 1.147 (1.147)  DataTime: 0.937 (0.937)  Loss:  1.0361 (1.0361)  F1: 46.2738 (46.2738)  Acc@1: 71.0938 (71.0938)  Acc@5: 90.6250 (90.6250)
Test: [  50/78]  Time: 0.196 (0.215)  DataTime: 0.000 (0.019)  Loss:  1.3525 (1.1819)  F1: 46.7667 (46.1478)  Acc@1: 64.8438 (66.4216)  Acc@5: 87.5000 (90.7782)
Test: [  78/78]  Time: 0.029 (0.206)  DataTime: 0.000 (0.012)  Loss:  1.3291 (1.1871)  F1:  9.6667 (46.3412)  Acc@1: 62.5000 (66.4100)  Acc@5: 87.5000 (90.7500)
metrics: OrderedDict([('loss', 1.1871), ('top1', 66.41), ('top5', 90.75), ('f1', 46.341)])
metrics_f1: 46.341
Test: [   0/78]  Time: 1.062 (1.062)  DataTime: 0.859 (0.859)  Loss:  1.1260 (1.1260)  F1: 44.9667 (44.9667)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.017)  Loss:  1.4238 (1.3344)  F1: 46.5714 (46.6805)  Acc@1: 64.8438 (66.9884)  Acc@5: 90.6250 (90.7475)
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.011)  Loss:  1.3818 (1.3297)  F1:  9.6667 (47.0372)  Acc@1: 62.5000 (67.2400)  Acc@5: 81.2500 (90.8400)
metrics: OrderedDict([('loss', 1.3297), ('top1', 67.24), ('top5', 90.84), ('f1', 47.037)])
metrics_f1: 47.037
Test: [   0/78]  Time: 1.196 (1.196)  DataTime: 0.834 (0.834)  Loss:  2.5371 (2.5371)  F1: 17.0095 (17.0095)  Acc@1: 32.0312 (32.0312)  Acc@5: 67.9688 (67.9688)
Test: [  50/78]  Time: 0.196 (0.216)  DataTime: 0.000 (0.017)  Loss:  2.7402 (2.6631)  F1: 19.8143 (18.1768)  Acc@1: 34.3750 (29.9632)  Acc@5: 68.7500 (66.9271)
Test: [  78/78]  Time: 0.029 (0.206)  DataTime: 0.000 (0.011)  Loss:  2.6270 (2.6706)  F1:  5.3333 (18.1197)  Acc@1: 37.5000 (29.6700)  Acc@5: 62.5000 (66.7800)
metrics: OrderedDict([('loss', 2.6706), ('top1', 29.67), ('top5', 66.78), ('f1', 18.12)])
metrics_f1: 18.12
Test: [   0/78]  Time: 0.989 (0.989)  DataTime: 0.743 (0.743)  Loss:  4.3711 (4.3711)  F1:  3.3429 ( 3.3429)  Acc@1: 12.5000 (12.5000)  Acc@5: 28.1250 (28.1250)
Test: [  50/78]  Time: 0.196 (0.212)  DataTime: 0.000 (0.015)  Loss:  4.3906 (4.3886)  F1:  3.3318 ( 2.9980)  Acc@1:  7.8125 ( 7.8278)  Acc@5: 28.1250 (27.9871)
Test: [  78/78]  Time: 0.029 (0.204)  DataTime: 0.000 (0.010)  Loss:  4.4180 (4.3926)  F1:  0.0000 ( 2.9508)  Acc@1:  0.0000 ( 7.6700)  Acc@5: 12.5000 (27.3900)
metrics: OrderedDict([('loss', 4.3926), ('top1', 7.67), ('top5', 27.39), ('f1', 2.951)])
metrics_f1: 2.951
score: [53, 79, 73, 72, 73, 28, 7]
DE:2 Acc@1: 69.1700 Acc@5: 91.3600                          Epoch_time: 1186.729s
cr f 1.337701145243376e-05 1.26804430732087e-05
data_time: 0.000 (0.002)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.010)  Loss:  1.4502 (1.3294)  F1:  9.6667 (47.1566)  Acc@1: 62.5000 (67.3900)  Acc@5: 81.2500 (90.8400)
metrics: OrderedDict([('loss', 1.3294), ('top1', 67.39), ('top5', 90.84), ('f1', 47.157)])
metrics_f1: 47.157
Test: [   0/78]  Time: 1.114 (1.114)  DataTime: 0.842 (0.842)  Loss:  4.3711 (4.3711)  F1:  3.3777 ( 3.3777)  Acc@1: 12.5000 (12.5000)  Acc@5: 28.1250 (28.1250)
Test: [  50/78]  Time: 0.196 (0.214)  DataTime: 0.000 (0.017)  Loss:  4.3906 (4.3887)  F1:  3.5136 ( 3.0594)  Acc@1:  8.5938 ( 7.9963)  Acc@5: 27.3438 (27.9565)
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.011)  Loss:  4.4141 (4.3927)  F1:  0.0000 ( 3.0522)  Acc@1:  0.0000 ( 7.8600)  Acc@5: 12.5000 (27.3700)
metrics: OrderedDict([('loss', 4.3927), ('top1', 7.86), ('top5', 27.37), ('f1', 3.052)])
metrics_f1: 3.052
score: [53, 78, 73, 72, 73, 28, 7]
DE:3 Acc@1: 69.1700 Acc@5: 91.3600                          Epoch_time: 1149.982s
cr f 1.6592175031058786e-05 1.4154504643409944e-05
data_time: 0.000 (0.002)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.322 (0.394)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
[tensor(52.8505), tensor(78.1925), tensor(73.1234), tensor(71.6592), tensor(73.0439), tensor(28.1686), tensor(7.0992)]
[1, 0, 1, 1, 1, 1, 1]
epoch:0, best_score:78.2325, best_idx:1,                      score: [tensor(52.8505), tensor(78.2325), tensor(73.1234), tensor(71.6592), tensor(73.0439), tensor(28.1686), tensor(7.0992)]
Test: [   0/78]  Time: 1.064 (1.064)  DataTime: 0.858 (0.858)  Loss:  1.5508 (1.5508)  F1: 38.0619 (38.0619)  Acc@1: 59.3750 (59.3750)  Acc@5: 85.9375 (85.9375)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.017)  Loss:  1.8730 (1.7457)  F1: 36.1476 (35.4466)  Acc@1: 53.1250 (52.6501)  Acc@5: 75.0000 (82.2917)
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.011)  Loss:  2.3613 (1.7474)  F1:  5.3333 (35.5509)  Acc@1: 37.5000 (52.6600)  Acc@5: 68.7500 (82.2200)
metrics: OrderedDict([('loss', 1.7474), ('top1', 52.66), ('top5', 82.22), ('f1', 35.551)])
metrics_f1: 35.551
Test: [   0/78]  Time: 0.794 (0.794)  DataTime: 0.592 (0.592)  Loss:  1.1289 (1.1289)  F1: 44.3214 (44.3214)  Acc@1: 67.9688 (67.9688)  Acc@5: 89.8438 (89.8438)
Test: [  50/78]  Time: 0.196 (0.210)  DataTime: 0.000 (0.014)  Loss:  1.3516 (1.2321)  F1: 46.9328 (46.4170)  Acc@1: 64.8438 (66.5901)  Acc@5: 90.6250 (90.7475)
Test: [  78/78]  Time: 0.029 (0.203)  DataTime: 0.000 (0.009)  Loss:  1.0527 (1.2256)  F1:  9.3333 (46.9052)  Acc@1: 62.5000 (66.8500)  Acc@5: 93.7500 (90.6900)
metrics: OrderedDict([('loss', 1.2256), ('top1', 66.85), ('top5', 90.69), ('f1', 46.905)])
metrics_f1: 46.905
Test: [   0/78]  Time: 0.905 (0.905)  DataTime: 0.608 (0.608)  Loss:  1.0527 (1.0527)  F1: 44.8786 (44.8786)  Acc@1: 69.5312 (69.5312)  Acc@5: 90.6250 (90.6250)
Test: [  50/78]  Time: 0.196 (0.210)  DataTime: 0.000 (0.013)  Loss:  1.3096 (1.1788)  F1: 46.6262 (46.2851)  Acc@1: 65.6250 (66.4982)  Acc@5: 89.0625 (90.5944)
Test: [  78/78]  Time: 0.029 (0.203)  DataTime: 0.000 (0.008)  Loss:  1.2109 (1.1921)  F1: 10.6667 (46.1218)  Acc@1: 68.7500 (66.1600)  Acc@5: 87.5000 (90.3300)
metrics: OrderedDict([('loss', 1.1921), ('top1', 66.16), ('top5', 90.33), ('f1', 46.122)])
metrics_f1: 46.122
Test: [   0/78]  Time: 0.845 (0.845)  DataTime: 0.614 (0.614)  Loss:  1.1523 (1.1523)  F1: 44.8476 (44.8476)  Acc@1: 69.5312 (69.5312)  Acc@5: 94.5312 (94.5312)
Test: [  50/78]  Time: 0.196 (0.209)  DataTime: 0.000 (0.012)  Loss:  1.4355 (1.3329)  F1: 47.7714 (47.0520)  Acc@1: 67.1875 (67.1262)  Acc@5: 89.8438 (90.6403)
Test: [  78/78]  Time: 0.029 (0.202)  DataTime: 0.000 (0.008)  Loss:  1.3828 (1.3316)  F1: 10.6667 (47.1417)  Acc@1: 68.7500 (67.0600)  Acc@5: 81.2500 (90.6900)
metrics: OrderedDict([('loss', 1.3316), ('top1', 67.06), ('top5', 90.69), ('f1', 47.142)])
metrics_f1: 47.142
Test: [   0/78]  Time: 1.021 (1.021)  DataTime: 0.812 (0.812)  Loss:  2.5273 (2.5273)  F1: 19.2000 (19.2000)  Acc@1: 34.3750 (34.3750)  Acc@5: 68.7500 (68.7500)
Test: [  50/78]  Time: 0.196 (0.212)  DataTime: 0.000 (0.016)  Loss:  2.7520 (2.6627)  F1: 19.7190 (18.4009)  Acc@1: 32.8125 (30.2083)  Acc@5: 67.1875 (66.8352)
Test: [  78/78]  Time: 0.028 (0.204)  DataTime: 0.000 (0.011)  Loss:  2.6680 (2.6703)  F1:  5.0000 (18.3455)  Acc@1: 37.5000 (29.8900)  Acc@5: 62.5000 (66.6900)
metrics: OrderedDict([('loss', 2.6703), ('top1', 29.89), ('top5', 66.69), ('f1', 18.346)])
metrics_f1: 18.346
Test: [   0/78]  Time: 1.138 (1.138)  DataTime: 0.790 (0.790)  Loss:  4.3672 (4.3672)  F1:  3.9038 ( 3.9038)  Acc@1: 12.5000 (12.5000)  Acc@5: 32.0312 (32.0312)
Test: [  50/78]  Time: 0.196 (0.214)  DataTime: 0.000 (0.016)  Loss:  4.3906 (4.3885)  F1:  3.0094 ( 2.8510)  Acc@1:  7.8125 ( 7.6593)  Acc@5: 27.3438 (27.8799)
Test: [  78/78]  Time: 0.029 (0.206)  DataTime: 0.000 (0.010)  Loss:  4.4141 (4.3926)  F1:  0.0000 ( 2.8881)  Acc@1:  0.0000 ( 7.6300)  Acc@5: 12.5000 (27.3900)
metrics: OrderedDict([('loss', 4.3926), ('top1', 7.63), ('top5', 27.39), ('f1', 2.888)])
metrics_f1: 2.888
score: [53, 78, 73, 72, 73, 28, 7]
DE:4 Acc@1: 69.1700 Acc@5: 91.3600                          Epoch_time: 1181.477s
cr f 1.9184056876424267e-05 1.6169271240127232e-05
data_time: 0.000 (0.003)  batch_time: 0.322 (0.395)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
data_time: 0.000 (0.002)  batch_time: 0.321 (0.394)  
data_time: 0.000 (0.004)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
[tensor(53.1246), tensor(78.3188), tensor(73.2773), tensor(71.8710), tensor(72.8708), tensor(28.0495), tensor(7.2191)]
[1, 0, 1, 1, 1, 0, 1]
epoch:0, best_score:78.3388, best_idx:1,                      score: [tensor(53.1246), tensor(78.3388), tensor(73.2773), tensor(71.8710), tensor(72.8708), tensor(28.0587), tensor(7.2191)]
Test: [   0/78]  Time: 1.139 (1.139)  DataTime: 0.932 (0.932)  Loss:  1.5654 (1.5654)  F1: 37.6952 (37.6952)  Acc@1: 59.3750 (59.3750)  Acc@5: 85.9375 (85.9375)
Test: [  50/78]  Time: 0.196 (0.215)  DataTime: 0.000 (0.019)  Loss:  1.8926 (1.7460)  F1: 36.4190 (35.2421)  Acc@1: 53.1250 (52.5429)  Acc@5: 75.7812 (82.3989)
Test: [  78/78]  Time: 0.029 (0.206)  DataTime: 0.000 (0.012)  Loss:  2.3672 (1.7459)  F1:  5.3333 (35.4764)  Acc@1: 37.5000 (52.6600)  Acc@5: 75.0000 (82.2900)
metrics: OrderedDict([('loss', 1.7459), ('top1', 52.66), ('top5', 82.29), ('f1', 35.476)])
metrics_f1: 35.476
Test: [   0/78]  Time: 0.831 (0.831)  DataTime: 0.580 (0.580)  Loss:  1.1035 (1.1035)  F1: 44.0191 (44.0191)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test: [  50/78]  Time: 0.196 (0.209)  DataTime: 0.000 (0.012)  Loss:  1.3789 (1.2352)  F1: 45.6119 (46.0042)  Acc@1: 61.7188 (66.2224)  Acc@5: 89.0625 (90.5484)
Test: [  78/78]  Time: 0.029 (0.202)  DataTime: 0.000 (0.008)  Loss:  0.9883 (1.2296)  F1: 11.0000 (46.6881)  Acc@1: 75.0000 (66.7100)  Acc@5: 93.7500 (90.6100)
metrics: OrderedDict([('loss', 1.2296), ('top1', 66.71), ('top5', 90.61), ('f1', 46.688)])
metrics_f1: 46.688
Test: [   0/78]  Time: 0.926 (0.926)  DataTime: 0.652 (0.652)  Loss:  1.0371 (1.0371)  F1: 45.9714 (45.9714)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.1875 (92.1875)
Test: [  50/78]  Time: 0.196 (0.211)  DataTime: 0.000 (0.013)  Loss:  1.2793 (1.1841)  F1: 47.0214 (46.0770)  Acc@1: 64.8438 (66.1918)  Acc@5: 88.2812 (90.7629)
Test: [  78/78]  Time: 0.029 (0.203)  DataTime: 0.000 (0.009)  Loss:  1.2979 (1.1942)  F1:  8.6667 (46.0147)  Acc@1: 56.2500 (65.9200)  Acc@5: 87.5000 (90.5700)
metrics: OrderedDict([('loss', 1.1942), ('top1', 65.92), ('top5', 90.57), ('f1', 46.015)])
metrics_f1: 46.015
Test: [   0/78]  Time: 1.028 (1.028)  DataTime: 0.646 (0.646)  Loss:  1.1436 (1.1436)  F1: 44.4214 (44.4214)  Acc@1: 68.7500 (68.7500)  Acc@5: 95.3125 (95.3125)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.013)  Loss:  1.4863 (1.3339)  F1: 42.8429 (46.8669)  Acc@1: 61.7188 (67.0343)  Acc@5: 91.4062 (90.7169)
Test: [  78/78]  Time: 0.029 (0.205)  DataTime: 0.000 (0.009)  Loss:  1.3145 (1.3270)  F1:  8.6667 (47.1700)  Acc@1: 56.2500 (67.3600)  Acc@5: 87.5000 (90.9300)
metrics: OrderedDict([('loss', 1.327), ('top1', 67.36), ('top5', 90.93), ('f1', 47.17)])
metrics_f1: 47.17
Test: [   0/78]  Time: 0.771 (0.771)  DataTime: 0.564 (0.564)  Loss:  4.3672 (4.3672)  F1:  3.6874 ( 3.6874)  Acc@1: 12.5000 (12.5000)  Acc@5: 26.5625 (26.5625)
Test: [  50/78]  Time: 0.196 (0.213)  DataTime: 0.000 (0.017)  Loss:  4.3906 (4.3882)  F1:  2.1396 ( 2.8910)  Acc@1:  7.8125 ( 7.7819)  Acc@5: 25.7812 (28.0484)
Test: [  78/78]  Time: 0.029 (0.204)  DataTime: 0.000 (0.011)  Loss:  4.4219 (4.3924)  F1:  0.0000 ( 2.9059)  Acc@1:  0.0000 ( 7.5700)  Acc@5: 12.5000 (27.5700)
metrics: OrderedDict([('loss', 4.3924), ('top1', 7.57), ('top5', 27.57), ('f1', 2.906)])
metrics_f1: 2.906
score: [53, 78, 73, 72, 73, 28, 7]
DE:5 Acc@1: 69.1700 Acc@5: 91.3600                          Epoch_time: 1164.886s
cr f 1.0679619437844799e-05 1.768357106388524e-05
data_time: 0.000 (0.003)  batch_time: 0.322 (0.394)  
data_time: 0.000 (0.003)  batch_time: 0.322 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.003)  batch_time: 0.321 (0.395)  
data_time: 0.000 (0.004)  batch_time: 0.321 (0.395)  
^C
Traceback (most recent call last):
  File "/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/main_cosde.py", line 522, in <module>
    main()
  File "/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/main_cosde.py", line 203, in main
    population,update_label,score = de(popsize, f, cr, population,model,loader_de,args)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/kaggle/working/inference/AML-Project/Evolution_Algorithm_Code/utils/tools/de.py", line 95, in de